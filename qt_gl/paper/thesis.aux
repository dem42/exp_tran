\relax 
\ifx\hyper@anchor\@undefined
\global \let \oldcontentsline\contentsline
\gdef \contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global \let \oldnewlabel\newlabel
\gdef \newlabel#1#2{\newlabelxx{#1}#2}
\gdef \newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\let \contentsline\oldcontentsline
\let \newlabel\oldnewlabel}
\else
\global \let \hyper@last\relax 
\fi

\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{6}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivation}{6}{section.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Contributions}{7}{section.1.2}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{8}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Deformable Models}{8}{section.2.1}}
\citation{FEM1pen}
\citation{FEM1ter}
\citation{FEMbook}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Physics Based Models}{9}{subsection.2.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1.1}Finite Element Method (FEM)}{9}{subsubsection.2.1.1.1}}
\newlabel{eq:FEMdisplacements}{{2.1}{9}{Finite Element Method (FEM)\relax }{equation.2.1}{}}
\citation{FEMbook}
\citation{FEMbook}
\citation{FEMbook}
\newlabel{eq:FEMstrain}{{2.2}{10}{Finite Element Method (FEM)\relax }{equation.2.2}{}}
\newlabel{eq:FEMequilibrium}{{2.3}{10}{Finite Element Method (FEM)\relax }{equation.2.3}{}}
\newlabel{eq:FEMstiffness}{{2.4}{10}{Finite Element Method (FEM)\relax }{equation.2.4}{}}
\newlabel{eq:FEMdynamic}{{2.5}{10}{Finite Element Method (FEM)\relax }{equation.2.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1.2}Modal Analysis}{10}{subsubsection.2.1.1.2}}
\newlabel{eq:FEMmodal}{{2.7}{11}{Modal Analysis\relax }{equation.2.7}{}}
\newlabel{eq:FEMbasis}{{2.8}{11}{Modal Analysis\relax }{equation.2.8}{}}
\newlabel{eq:FEMdiag}{{2.11}{11}{Modal Analysis\relax }{equation.2.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1.3}Recovering shape with FEM}{11}{subsubsection.2.1.1.3}}
\newlabel{eq:FEMgenerate}{{2.12}{11}{Recovering shape with FEM\relax }{equation.2.12}{}}
\newlabel{eq:FEMload}{{2.13}{11}{Recovering shape with FEM\relax }{equation.2.13}{}}
\citation{eigenfaces91}
\citation{bishop}
\citation{vienna}
\citation{vienna}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Statistical Models}{12}{subsection.2.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2.1}PCA and Eigenfaces}{12}{subsubsection.2.1.2.1}}
\newlabel{eq:pca_eig}{{2.15}{12}{PCA and Eigenfaces\relax }{equation.2.15}{}}
\newlabel{eq:pca}{{2.16}{12}{PCA and Eigenfaces\relax }{equation.2.16}{}}
\citation{eigenfaces91}
\citation{blanz1}
\citation{blanz2}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces  Using the eigenfaces we can represent an image as a linear combination of the eigenfaces. Taken from \cite  {vienna}. }}{13}{figure.2.1}}
\newlabel{gr:eigenfaces}{{2.1}{13}{ Using the eigenfaces we can represent an image as a linear combination of the eigenfaces. Taken from \cite {vienna}. \relax }{figure.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2.2}Morphable Model}{13}{subsubsection.2.1.2.2}}
\citation{activeApp04}
\newlabel{eq:morhpable_pca}{{2.20}{14}{Morphable Model\relax }{equation.2.20}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2.3}Combined Models of Shape and Appearance}{14}{subsubsection.2.1.2.3}}
\newlabel{eq:shape}{{2.21}{14}{Combined Models of Shape and Appearance\relax }{equation.2.21}{}}
\newlabel{eq:text}{{2.22}{14}{Combined Models of Shape and Appearance\relax }{equation.2.22}{}}
\citation{cootesOverview01}
\citation{cootesOverview01}
\citation{cootesOverview01}
\citation{cootesOverview01}
\newlabel{gth:shape_mod}{{2.23}{15}{Combined Models of Shape and Appearance\relax }{equation.2.23}{}}
\newlabel{gth:texture_mod}{{2.24}{15}{Combined Models of Shape and Appearance\relax }{equation.2.24}{}}
\@writefile{toc}{\contentsline {paragraph}{Active Shape Model.}{15}{section*.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces  Active Shape Model iterations shown on finding the shape of a previously unseen face. Taken from \cite  {cootesOverview01}. }}{15}{figure.2.2}}
\newlabel{gr:asm}{{2.2}{15}{ Active Shape Model iterations shown on finding the shape of a previously unseen face. Taken from \cite {cootesOverview01}. \relax }{figure.2.2}{}}
\citation{activeApp04}
\citation{activeApp04}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces  Incorrect convergence of the ASM when the search is initialized incorrectly. This can happen when the face is not centered in the image or when the search does not begin in the center of the image. Taken from \cite  {cootesOverview01}. }}{16}{figure.2.3}}
\newlabel{gr:bad_asm}{{2.3}{16}{ Incorrect convergence of the ASM when the search is initialized incorrectly. This can happen when the face is not centered in the image or when the search does not begin in the center of the image. Taken from \cite {cootesOverview01}. \relax }{figure.2.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Active Appearance Model.}{16}{section*.3}}
\citation{activeApp04}
\citation{Ter1}
\citation{Ter2}
\citation{Ter3}
\citation{multilinear}
\citation{matcalc}
\citation{matrix}
\citation{kronecker}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces  Active Appearance Model iterations shown when searching for previously unseen faces. Taken from \cite  {activeApp04}. }}{17}{figure.2.4}}
\newlabel{gr:amm}{{2.4}{17}{ Active Appearance Model iterations shown when searching for previously unseen faces. Taken from \cite {activeApp04}. \relax }{figure.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Tensor Models}{17}{subsection.2.1.3}}
\citation{multilinear}
\citation{multilinear}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3.1}Multilinear Algebra}{18}{subsubsection.2.1.3.1}}
\@writefile{toc}{\contentsline {paragraph}{Tensors.}{18}{section*.4}}
\@writefile{toc}{\contentsline {paragraph}{Tensor Flattening.}{18}{section*.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces  Flattening of the $(I_1\times I_2 \times I_3)$-tensor $\mathcal  {A}$ into three matrices; the $(I_1\times I_2 I_3)$-matrix $\mathbf  {A_{(1)}}$, the $(I_2\times I_3 I_1)$-matrix $\mathbf  {A_{(2)}}$ and the $(I_3\times I_1 I_2)$-matrix $\mathbf  {A_{(3)}}$. Taken from \cite  {multilinear}.}}{18}{figure.2.5}}
\newlabel{fg:flat}{{2.5}{18}{ Flattening of the $(I_1\times I_2 \times I_3)$-tensor $\mathcal {A}$ into three matrices; the $(I_1\times I_2 I_3)$-matrix $\mathbf {A_{(1)}}$, the $(I_2\times I_3 I_1)$-matrix $\mathbf {A_{(2)}}$ and the $(I_3\times I_1 I_2)$-matrix $\mathbf {A_{(3)}}$. Taken from \cite {multilinear}}{figure.2.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Kronecker product.}{19}{section*.6}}
\newlabel{eq:kronecker}{{2.26}{19}{Kronecker product}{equation.2.26}{}}
\@writefile{toc}{\contentsline {subparagraph}{Properties.}{19}{section*.7}}
\newlabel{eq:kron_mult}{{2.27}{19}{Properties}{equation.2.27}{}}
\@writefile{toc}{\contentsline {subparagraph}{Proof.}{19}{section*.8}}
\newlabel{eq:krontran}{{2.28}{19}{Proof}{equation.2.28}{}}
\@writefile{toc}{\contentsline {subparagraph}{Proof.}{19}{section*.9}}
\newlabel{eq:kron_inv}{{2.29}{19}{Proof}{equation.2.29}{}}
\@writefile{toc}{\contentsline {subparagraph}{Proof.}{19}{section*.10}}
\newlabel{eq:kron_ortho}{{2.30}{19}{Proof}{equation.2.30}{}}
\citation{multilinear}
\citation{multilinear}
\citation{multilinear}
\@writefile{toc}{\contentsline {paragraph}{Frobenius Norm.}{20}{section*.11}}
\newlabel{eq:frob}{{2.31}{20}{Frobenius Norm}{equation.2.31}{}}
\@writefile{toc}{\contentsline {paragraph}{Mode-$n$ product.}{20}{section*.12}}
\newlabel{eq:modemult}{{2.32}{20}{Mode-$n$ product}{equation.2.32}{}}
\newlabel{eq:kronmodemult}{{2.33}{20}{Mode-$n$ product}{equation.2.33}{}}
\@writefile{toc}{\contentsline {paragraph}{High Order Singular Value Decomposition (HOSVD).}{20}{section*.13}}
\newlabel{eq:HOSVD}{{2.34}{20}{High Order Singular Value Decomposition (HOSVD)}{equation.2.34}{}}
\newlabel{eq:core_tensor}{{2.35}{20}{High Order Singular Value Decomposition (HOSVD)}{equation.2.35}{}}
\citation{Ter1}
\citation{faceTransfer05}
\citation{faceTransfer05}
\citation{faceTransfer05}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces The HOSVD decomposition of 3$^{rd}$ order tensor $\mathcal  {A}$ into three mode matrices $\mathbf  {U}^{(1)}$, $\mathbf  {U}^{(2)}$, $\mathbf  {U}^{(3)}$ and the core tensor $\mathcal  {S}$. The shaded part of the core tensor and the mode matrices represents a the truncated versions of these multilinear operators. The composition of the truncated mode matrices and the truncated tensor approximates the tensor $\mathcal  {A}$. Taken from \cite  {multilinear}. }}{21}{figure.2.6}}
\newlabel{fg:hosvd}{{2.6}{21}{The HOSVD decomposition of 3$^{rd}$ order tensor $\mathcal {A}$ into three mode matrices $\mathbf {U}^{(1)}$, $\mathbf {U}^{(2)}$, $\mathbf {U}^{(3)}$ and the core tensor $\mathcal {S}$. The shaded part of the core tensor and the mode matrices represents a the truncated versions of these multilinear operators. The composition of the truncated mode matrices and the truncated tensor approximates the tensor $\mathcal {A}$. Taken from \cite {multilinear}. \relax }{figure.2.6}{}}
\@writefile{toc}{\contentsline {paragraph}{HOSVD Algorithm.}{21}{section*.14}}
\newlabel{eq:core}{{2.36}{21}{HOSVD Algorithm}{equation.2.36}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3.2}Tensor-Based Model}{21}{subsubsection.2.1.3.2}}
\newlabel{works}{{2.1.3.2}{21}{Tensor-Based Model\relax }{subsubsection.2.1.3.2}{}}
\citation{sdm}
\citation{jacey}
\citation{lda}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Multilinear face model showing how different attributes change along the modes. Taken from \cite  {faceTransfer05}. }}{22}{figure.2.7}}
\newlabel{gr:tensor}{{2.7}{22}{Multilinear face model showing how different attributes change along the modes. Taken from \cite {faceTransfer05}. \relax }{figure.2.7}{}}
\newlabel{eq:multilin_face}{{2.37}{22}{Tensor-Based Model\relax }{equation.2.37}{}}
\newlabel{eq:generative_model}{{2.38}{22}{Tensor-Based Model\relax }{equation.2.38}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3.3}Tensor-based Statistical Discriminant Method}{22}{subsubsection.2.1.3.3}}
\citation{opencv}
\citation{opencv}
\newlabel{eq:lda}{{2.39}{23}{Tensor-based Statistical Discriminant Method\relax }{equation.2.39}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}3D Pose Estimation}{23}{section.2.2}}
\newlabel{s:3dpose}{{2.2}{23}{3D Pose Estimation\relax }{section.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Camera Model}{23}{subsection.2.2.1}}
\newlabel{s:camera}{{2.2.1}{23}{Camera Model\relax }{subsection.2.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1.1}Perspective Camera Model}{23}{subsubsection.2.2.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Perspective projection camera model with the image plane behind the camera. Taken from \cite  {opencv}.}}{24}{figure.2.8}}
\newlabel{fg:pin}{{2.8}{24}{Perspective projection camera model with the image plane behind the camera. Taken from \cite {opencv}}{figure.2.8}{}}
\newlabel{eq:pinCoord}{{2.40}{24}{Perspective Camera Model\relax }{equation.2.40}{}}
\newlabel{eq:projective}{{2.41}{24}{Perspective Camera Model\relax }{equation.2.41}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1.2}Orthogonal Camera Model}{24}{subsubsection.2.2.1.2}}
\citation{projection}
\citation{projection}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1.3}Weak Perspective Camera Model}{25}{subsubsection.2.2.1.3}}
\newlabel{s:weak}{{2.2.1.3}{25}{Weak Perspective Camera Model\relax }{subsubsection.2.2.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Weak perspective projection is a scaled orthographic projection. The image obtained by orthographic projection is scaled by the constant $f/Z_{avg}$. Taken from \cite  {projection}.}}{25}{figure.2.9}}
\newlabel{fg:weakOrtho}{{2.9}{25}{Weak perspective projection is a scaled orthographic projection. The image obtained by orthographic projection is scaled by the constant $f/Z_{avg}$. Taken from \cite {projection}}{figure.2.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Rotation and Translation}{25}{subsection.2.2.2}}
\citation{graphics}
\citation{graphics}
\citation{matrix}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces  Mapping points from object coordinates to camera coordinates using rotation and translation. The displacement of the origin of the camera system from the origin of the object system is $\mathbf  {C}$. The camera is viewing in the direction of the vector $d$. Taken from \cite  {graphics}.}}{26}{figure.2.10}}
\newlabel{fg:objCam}{{2.10}{26}{ Mapping points from object coordinates to camera coordinates using rotation and translation. The displacement of the origin of the camera system from the origin of the object system is $\mathbf {C}$. The camera is viewing in the direction of the vector $d$. Taken from \cite {graphics}}{figure.2.10}{}}
\newlabel{eq:givens}{{2.43}{26}{Rotation and Translation\relax }{equation.2.43}{}}
\newlabel{eq:rotations}{{2.45}{26}{Rotation and Translation\relax }{equation.2.45}{}}
\citation{opencv}
\citation{opencv}
\newlabel{eq:rotated}{{2.46}{27}{Rotation and Translation\relax }{equation.2.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Transforming one point into another by rotating the coordinate system counterclockwise by $\theta $ radians. The point $[x,y]^T$ can be written as $[x,0]^T+[0,y]^T.$ These components are then individually transformed by projecting them onto the axes of the new coordinate system $(X',Y')$ to obtain the new point $[x',y']^T$. The new point is the result of turning the original point clockwise by $\theta $ radians. Take from \cite  {opencv}.}}{27}{figure.2.11}}
\newlabel{fg:rotations}{{2.11}{27}{Transforming one point into another by rotating the coordinate system counterclockwise by $\theta $ radians. The point $[x,y]^T$ can be written as $[x,0]^T+[0,y]^T.$ These components are then individually transformed by projecting them onto the axes of the new coordinate system $(X',Y')$ to obtain the new point $[x',y']^T$. The new point is the result of turning the original point clockwise by $\theta $ radians. Take from \cite {opencv}}{figure.2.11}{}}
\citation{POSIT}
\citation{opencv}
\newlabel{eq:rottran}{{2.47}{28}{Rotation and Translation\relax }{equation.2.47}{}}
\newlabel{eq:jointrottran}{{2.48}{28}{Rotation and Translation\relax }{equation.2.48}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Pose estimation with the POSIT algorithm}{28}{subsection.2.2.3}}
\newlabel{posit}{{2.2.3}{28}{Pose estimation with the POSIT algorithm\relax }{subsection.2.2.3}{}}
\citation{kanade}
\citation{kanade2}
\citation{kanade3}
\citation{kanade4}
\newlabel{eq:posit}{{2.50}{29}{Pose estimation with the POSIT algorithm\relax }{equation.2.50}{}}
\newlabel{eq:posit2}{{2.51}{29}{Pose estimation with the POSIT algorithm\relax }{equation.2.51}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Feature Point Tracking}{29}{section.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Kanade-Lucas-Tomasi Feature Tracker}{29}{subsection.2.3.1}}
\newlabel{s:kanade}{{2.3.1}{29}{Kanade-Lucas-Tomasi Feature Tracker\relax }{subsection.2.3.1}{}}
\newlabel{fg:apple}{{2.3.1}{29}{Kanade-Lucas-Tomasi Feature Tracker\relax }{subsection.2.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces  The image registration problem. The task is to find the disparity vector $h$.}}{29}{figure.2.12}}
\citation{kanade4}
\citation{faceTransfer05}
\newlabel{eq:kanade1}{{2.53}{30}{Kanade-Lucas-Tomasi Feature Tracker\relax }{equation.2.53}{}}
\newlabel{eq:kanade2}{{2.55}{30}{Kanade-Lucas-Tomasi Feature Tracker\relax }{equation.2.55}{}}
\newlabel{eq:kanade3}{{2.56}{30}{Kanade-Lucas-Tomasi Feature Tracker\relax }{equation.2.56}{}}
\newlabel{eq:kanade4}{{2.57}{30}{Kanade-Lucas-Tomasi Feature Tracker\relax }{equation.2.57}{}}
\citation{Press1992}
\citation{nnls}
\citation{nnls2}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Optimization}{31}{section.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Least Squares and Non Negative Least Squares}{31}{subsection.2.4.1}}
\newlabel{eq:nnls}{{2.60}{31}{Least Squares and Non Negative Least Squares\relax }{equation.2.60}{}}
\newlabel{eq:nnls2}{{2.61}{31}{Least Squares and Non Negative Least Squares\relax }{equation.2.61}{}}
\newlabel{eq:nnls2}{{2.62}{31}{Least Squares and Non Negative Least Squares\relax }{equation.2.62}{}}
\newlabel{eq:nnls3}{{2.63}{31}{Least Squares and Non Negative Least Squares\relax }{equation.2.63}{}}
\citation{Nelder2009}
\citation{Press1992}
\newlabel{eq:nnls4}{{2.64}{32}{Least Squares and Non Negative Least Squares\relax }{equation.2.64}{}}
\newlabel{eq:nnls5}{{2.65}{32}{Least Squares and Non Negative Least Squares\relax }{equation.2.65}{}}
\newlabel{a:sca}{{2.4.1}{32}{Least Squares and Non Negative Least Squares\relax }{equation.2.68}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Sequential Coordinate-wise Non-negativity Least Squares Algorithm}}{32}{algorithm.\theHalgorithm }}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Nelder Mead Downhill Simplex}{32}{subsection.2.4.2}}
\newlabel{s:nelder}{{2.4.2}{32}{Nelder Mead Downhill Simplex\relax }{subsection.2.4.2}{}}
\citation{Press1992}
\citation{Nelder2009}
\citation{Press1992}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2.1}The Downhill Simplex Algorithm}{33}{subsubsection.2.4.2.1}}
\newlabel{eq:right_angle_simplex}{{2.69}{33}{The Downhill Simplex Algorithm\relax }{equation.2.69}{}}
\newlabel{eq:centroid}{{2.70}{33}{The Downhill Simplex Algorithm\relax }{Item.1}{}}
\newlabel{eq:reflection}{{2.71}{33}{The Downhill Simplex Algorithm\relax }{Item.2}{}}
\newlabel{eq:expansion}{{2.72}{33}{The Downhill Simplex Algorithm\relax }{Item.3}{}}
\citation{Nelder2009}
\citation{Nelder2009}
\citation{Press1992}
\citation{Nelder2009}
\citation{Press1992}
\newlabel{eq:contraction}{{2.73}{34}{The Downhill Simplex Algorithm\relax }{Item.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Geometric interpretations of the simplex transformations. Taken from \cite  {Nelder2009}.}}{34}{figure.2.13}}
\newlabel{fg:amoeba}{{2.13}{34}{Geometric interpretations of the simplex transformations. Taken from \cite {Nelder2009}}{figure.2.13}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Design}{35}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{design}{{3}{35}{Design\relax }{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Design Challenges}{35}{section.3.1}}
\citation{opencv}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Frameworks and APIs}{36}{section.3.2}}
\citation{opengl}
\citation{ICP}
\citation{deformTri}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}OpenCV}{37}{subsection.3.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}OpenGL}{37}{subsection.3.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Qt}{37}{subsection.3.2.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Pre-processing}{37}{section.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Correspondence}{37}{subsection.3.3.1}}
\citation{binghamton}
\citation{binghamton}
\citation{binghamton}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Database}{38}{subsection.3.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Sample 3D face scans from the Binghamton database along with the corresponding texture maps. Taken from \cite  {binghamton}.}}{38}{figure.3.1}}
\newlabel{fg:binghamton}{{3.1}{38}{Sample 3D face scans from the Binghamton database along with the corresponding texture maps. Taken from \cite {binghamton}}{figure.3.1}{}}
\citation{jacey}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Model Construction}{39}{section.3.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Data Tensor}{39}{subsection.3.4.1}}
\newlabel{s:datatesnor}{{3.4.1}{39}{Data Tensor\relax }{subsection.3.4.1}{}}
\newlabel{a:load}{{3.4.1}{39}{Data Tensor\relax }{subsection.3.4.1}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Loading the Data Tensor}}{39}{algorithm.\theHalgorithm }}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Flattening a Tensor along the identity mode space}}{40}{algorithm.\theHalgorithm }}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Computing the HOSVD}{40}{subsection.3.4.2}}
\newlabel{s:hosvd}{{3.4.2}{40}{Computing the HOSVD\relax }{subsection.3.4.2}{}}
\newlabel{eq:generative_model2}{{3.1}{40}{Computing the HOSVD\relax }{equation.3.1}{}}
\newlabel{eq:model}{{3.2}{40}{Computing the HOSVD\relax }{equation.3.2}{}}
\newlabel{eq:svdi}{{3.3}{40}{Computing the HOSVD\relax }{equation.3.3}{}}
\newlabel{eq:svde}{{3.4}{40}{Computing the HOSVD\relax }{equation.3.4}{}}
\newlabel{eq:trick}{{3.6}{41}{Computing the HOSVD\relax }{equation.3.6}{}}
\newlabel{eq:trick2}{{3.7}{41}{Computing the HOSVD\relax }{equation.3.7}{}}
\newlabel{eq:hosvd2}{{3.9}{41}{Computing the HOSVD\relax }{equation.3.9}{}}
\newlabel{eq:hosvd4}{{3.10}{41}{Computing the HOSVD\relax }{equation.3.10}{}}
\@writefile{toc}{\contentsline {paragraph}{HOSVD algorithm}{42}{section*.15}}
\newlabel{eq:hosvdsvdi}{{3.11}{42}{HOSVD algorithm\relax }{equation.3.11}{}}
\newlabel{eq:hosvdsvde}{{3.12}{42}{HOSVD algorithm\relax }{equation.3.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Generating new faces}{42}{subsection.3.4.3}}
\newlabel{eq:gen}{{3.14}{42}{Generating new faces\relax }{equation.3.14}{}}
\newlabel{eq:gen0.1}{{3.15}{42}{Generating new faces\relax }{equation.3.15}{}}
\newlabel{eq:gen1}{{3.16}{42}{Generating new faces\relax }{equation.3.16}{}}
\newlabel{eq:gen2}{{3.18}{42}{Generating new faces\relax }{equation.3.18}{}}
\newlabel{eq:gen4}{{3.21}{43}{Generating new faces\relax }{equation.3.21}{}}
\@writefile{toc}{\contentsline {paragraph}{Summary.}{43}{section*.16}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Model Parameter Estimation}{43}{section.3.5}}
\citation{viola}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Locating Feature Points}{44}{subsection.3.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Three newly generated faces with twenty feature points (denoted by the red spheres). These feature points define the correspondence between the model and the image.}}{45}{figure.3.2}}
\newlabel{fg:featurePoints}{{3.2}{45}{Three newly generated faces with twenty feature points (denoted by the red spheres). These feature points define the correspondence between the model and the image}{figure.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces The user selects points in the image which correspond to the feature points on the model (see figure \ref  {fg:featurePoints} ).}}{45}{figure.3.3}}
\newlabel{fg:featurePoints2}{{3.3}{45}{The user selects points in the image which correspond to the feature points on the model (see figure \ref {fg:featurePoints} )}{figure.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Tracking Feature Points}{45}{subsection.3.5.2}}
\citation{kanade4}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Camera Parameters}{46}{subsection.3.5.3}}
\newlabel{eq:projective}{{3.22}{46}{Camera Parameters\relax }{equation.3.22}{}}
\citation{zhang}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Locating feature points in a chessboard pattern.}}{47}{figure.3.4}}
\newlabel{fg:chessboard}{{3.4}{47}{Locating feature points in a chessboard pattern}{figure.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.4}Minimizing the Error Function}{47}{subsection.3.5.4}}
\newlabel{s:minerror}{{3.5.4}{47}{Minimizing the Error Function\relax }{subsection.3.5.4}{}}
\newlabel{eq:fit0}{{3.23}{47}{Minimizing the Error Function\relax }{equation.3.23}{}}
\newlabel{eq:fit1}{{3.24}{47}{Minimizing the Error Function\relax }{equation.3.24}{}}
\newlabel{eq:fit2}{{3.25}{48}{Minimizing the Error Function\relax }{equation.3.25}{}}
\newlabel{eq:fit3}{{3.26}{48}{Minimizing the Error Function\relax }{equation.3.26}{}}
\newlabel{eq:fit5}{{3.27}{48}{Minimizing the Error Function\relax }{equation.3.27}{}}
\newlabel{eq:fit6}{{3.28}{48}{Minimizing the Error Function\relax }{equation.3.28}{}}
\newlabel{eq:fit7}{{3.29}{48}{Minimizing the Error Function\relax }{equation.3.29}{}}
\newlabel{eq:fit8}{{3.30}{48}{Minimizing the Error Function\relax }{equation.3.30}{}}
\citation{ifemcolorado}
\newlabel{eq:fit9}{{3.31}{49}{Minimizing the Error Function\relax }{equation.3.31}{}}
\@writefile{toc}{\contentsline {paragraph}{Error function.}{49}{section*.17}}
\newlabel{eq:fit10}{{3.32}{49}{Error function}{equation.3.32}{}}
\newlabel{eq:fit11}{{3.33}{49}{Error function}{equation.3.33}{}}
\citation{matcalc}
\newlabel{eq:opt0}{{3.34}{50}{Error function}{equation.3.34}{}}
\newlabel{eq:opt1}{{3.37}{50}{Error function}{equation.3.37}{}}
\newlabel{eq:opt2}{{3.38}{50}{Error function}{equation.3.38}{}}
\citation{Press1992}
\citation{faceTransfer05}
\newlabel{eq:nonlin1}{{3.42}{52}{Error function}{equation.3.42}{}}
\newlabel{eq:H}{{3.43}{52}{Error function}{equation.3.43}{}}
\newlabel{eq:nonlin2}{{3.44}{52}{Error function}{equation.3.44}{}}
\newlabel{eq:G}{{3.45}{52}{Error function}{equation.3.45}{}}
\@writefile{toc}{\contentsline {paragraph}{Coordinate-Descent Method}{52}{section*.18}}
\citation{blanz1}
\citation{jacey}
\newlabel{a:coorddesc}{{3.5.4}{53}{Coordinate-Descent Method\relax }{section*.18}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces Coordinate-descent for one frame}}{53}{algorithm.\theHalgorithm }}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.5}Overfitting}{53}{subsection.3.5.5}}
\newlabel{s:overfitting}{{3.5.5}{53}{Overfitting\relax }{subsection.3.5.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Regularization.}{54}{section*.19}}
\newlabel{eq:regular}{{3.46}{54}{Regularization}{equation.3.46}{}}
\@writefile{toc}{\contentsline {paragraph}{Constrained Optimization.}{54}{section*.20}}
\newlabel{eq:optprob}{{3.49}{55}{Constrained Optimization}{equation.3.49}{}}
\newlabel{eq:nonneg1}{{3.52}{55}{Constrained Optimization}{equation.3.52}{}}
\newlabel{eq:nonneg2}{{3.53}{55}{Constrained Optimization}{equation.3.53}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.6}Fitting Algorithm}{55}{subsection.3.5.6}}
\newlabel{s:fitalgo}{{3.5.6}{55}{Fitting Algorithm\relax }{subsection.3.5.6}{}}
\@writefile{toc}{\contentsline {paragraph}{Multi-Frame Coordinate Descent.}{55}{section*.21}}
\@writefile{toc}{\contentsline {paragraph}{Feature point generation.}{56}{section*.22}}
\newlabel{s:fit}{{3.5.6}{56}{Expression Transfer Fitting Algorithm. \relax }{section*.23}{}}
\@writefile{toc}{\contentsline {paragraph}{Expression Transfer Fitting Algorithm. }{56}{section*.23}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Expression Transfer}{57}{section.3.6}}
\newlabel{s:exptranalgo}{{3.6}{57}{Expression Transfer\relax }{section.3.6}{}}
\citation{perez}
\citation{poisson}
\citation{perez}
\@writefile{toc}{\contentsline {paragraph}{Poisson Cloning.}{58}{section*.24}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces The seamless blending of regions into a target image using Poisson image editing.}}{58}{figure.3.5}}
\newlabel{fg:poisson}{{3.5}{58}{The seamless blending of regions into a target image using Poisson image editing}{figure.3.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Expression transfer algorithm.}{58}{section*.25}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}System Architecture}{59}{section.3.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces System architecture of the expression transfer application.}}{59}{figure.3.6}}
\newlabel{fg:mvc}{{3.6}{59}{System architecture of the expression transfer application}{figure.3.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.1}View Layer}{59}{subsection.3.7.1}}
\@writefile{toc}{\contentsline {paragraph}{OpenGL widget}{59}{section*.26}}
\@writefile{toc}{\contentsline {paragraph}{Interactive Image Hierarchy}{60}{section*.27}}
\@writefile{toc}{\contentsline {paragraph}{Main Window}{60}{section*.28}}
\@writefile{toc}{\contentsline {paragraph}{GUI}{60}{section*.29}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces The face tab part of the GUI which allows the user to view and move the 3D face.}}{60}{figure.3.7}}
\newlabel{fg:facetab}{{3.7}{60}{The face tab part of the GUI which allows the user to view and move the 3D face}{figure.3.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces The video tab which provides model fitting and feature point tracking functionality.}}{61}{figure.3.8}}
\newlabel{fg:videotab}{{3.8}{61}{The video tab which provides model fitting and feature point tracking functionality}{figure.3.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.2}Model Layer}{61}{subsection.3.7.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces UML class diagram of the model layer.}}{61}{figure.3.9}}
\newlabel{fg:modellayer}{{3.9}{61}{UML class diagram of the model layer}{figure.3.9}{}}
\@writefile{toc}{\contentsline {paragraph}{Model Construction}{62}{section*.30}}
\@writefile{toc}{\contentsline {paragraph}{Model Fitting}{62}{section*.31}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces The sequence diagram showing an invocation of the \texttt  {VideoProcessor} thread.}}{62}{figure.3.10}}
\newlabel{fg:videoproc}{{3.10}{62}{The sequence diagram showing an invocation of the \texttt {VideoProcessor} thread}{figure.3.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.3}Controller Layer}{63}{subsection.3.7.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Results and Evaluation}{64}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Face Generation}{64}{section.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces The graphic shows six expressions of the seven expressions present in the database. From left to right, top to bottom: neutral, surprise, sadness, fear, happiness and disgust.}}{64}{figure.4.1}}
\newlabel{fg:facegen}{{4.1}{64}{The graphic shows six expressions of the seven expressions present in the database. From left to right, top to bottom: neutral, surprise, sadness, fear, happiness and disgust}{figure.4.1}{}}
\newlabel{sfg:happyneg}{{4.2a}{65}{Subfigure 4 4.2a\relax }{subfigure.4.2.1}{}}
\newlabel{sub@sfg:happyneg}{{(a)}{a}{Subfigure 4 4.2a\relax }{subfigure.4.2.1}{}}
\newlabel{sfg:neghappy}{{4.2b}{65}{Subfigure 4 4.2b\relax }{subfigure.4.2.2}{}}
\newlabel{sub@sfg:neghappy}{{(b)}{b}{Subfigure 4 4.2b\relax }{subfigure.4.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces New expressions are generated by moving the points in the direction of one of the vectors of the expression mode matrices. This movement is mathematically equivalent to taking a linear combination.}}{65}{figure.4.2}}
\newlabel{fg:faceaddsub}{{4.2}{65}{New expressions are generated by moving the points in the direction of one of the vectors of the expression mode matrices. This movement is mathematically equivalent to taking a linear combination}{figure.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Generating new face through linear interpolation of the original faces.}}{65}{figure.4.3}}
\newlabel{fg:faceinter}{{4.3}{65}{Generating new face through linear interpolation of the original faces}{figure.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Linear interpolation between subjects from the Binghamton database.}}{66}{figure.4.4}}
\newlabel{fg:faceidinter}{{4.4}{66}{Linear interpolation between subjects from the Binghamton database}{figure.4.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces The movement of feature points (designated by red spheres).}}{66}{figure.4.5}}
\newlabel{fg:featureinter}{{4.5}{66}{The movement of feature points (designated by red spheres)}{figure.4.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Tracking Results}{67}{section.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Tracking of feature point using a $3 \times 3$ window size. A large number of feature points jump into incorrect positions, since the window size is too small.}}{67}{figure.4.6}}
\newlabel{fg:3opt}{{4.6}{67}{Tracking of feature point using a $3 \times 3$ window size. A large number of feature points jump into incorrect positions, since the window size is too small}{figure.4.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Tracking of feature point using a $50 \times 50$ window size. The features do not follow their true counterparts because the window size is too large.}}{68}{figure.4.7}}
\newlabel{fg:50opt}{{4.7}{68}{Tracking of feature point using a $50 \times 50$ window size. The features do not follow their true counterparts because the window size is too large}{figure.4.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Best tracking results obtained using a $15 \times 15$ window size.}}{68}{figure.4.8}}
\newlabel{fg:8opt}{{4.8}{68}{Best tracking results obtained using a $15 \times 15$ window size}{figure.4.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Fitting Algorithm Results}{69}{section.4.3}}
\@writefile{toc}{\contentsline {paragraph}{Feature point selection.}{69}{section*.32}}
\newlabel{fg:nonep}{{4.9a}{69}{Subfigure 4 4.9a\relax }{subfigure.4.9.1}{}}
\newlabel{sub@fg:nonep}{{(a)}{a}{Subfigure 4 4.9a\relax }{subfigure.4.9.1}{}}
\newlabel{fg:manypoints}{{4.9b}{69}{Subfigure 4 4.9b\relax }{subfigure.4.9.2}{}}
\newlabel{sub@fg:manypoints}{{(b)}{b}{Subfigure 4 4.9b\relax }{subfigure.4.9.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces The above images illustrate the trade-off between quality of optimization and the introduced bias. With too few points the identity estimate can never be very accurate. With too many points, the result becomes biased for the first frame alignment face which is different from the one in the image.}}{69}{figure.4.9}}
\newlabel{fg:points}{{4.9}{69}{The above images illustrate the trade-off between quality of optimization and the introduced bias. With too few points the identity estimate can never be very accurate. With too many points, the result becomes biased for the first frame alignment face which is different from the one in the image}{figure.4.9}{}}
\@writefile{toc}{\contentsline {paragraph}{Optimization scheme.}{70}{section*.33}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces The convergence behaviour of the two fitting algorithm variations. Regularization converges to a lower error value faster but often produces unrealistic face scans for low values of the regularization parameter $\lambda $.}}{70}{figure.4.10}}
\newlabel{fg:convergence}{{4.10}{70}{The convergence behaviour of the two fitting algorithm variations. Regularization converges to a lower error value faster but often produces unrealistic face scans for low values of the regularization parameter $\lambda $}{figure.4.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces The result of fitting the model to an image using the various fitting algorithms.}}{70}{figure.4.11}}
\newlabel{fg:optimization}{{4.11}{70}{The result of fitting the model to an image using the various fitting algorithms}{figure.4.11}{}}
\newlabel{fg:meanface}{{4.12b}{71}{Subfigure 4 4.12b\relax }{subfigure.4.12.2}{}}
\newlabel{sub@fg:meanface}{{(b)}{b}{Subfigure 4 4.12b\relax }{subfigure.4.12.2}{}}
\newlabel{fg:inhuman}{{4.12c}{71}{Subfigure 4 4.12c\relax }{subfigure.4.12.3}{}}
\newlabel{sub@fg:inhuman}{{(c)}{c}{Subfigure 4 4.12c\relax }{subfigure.4.12.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces Results obtained from applying the regularized fitting algorithm.}}{71}{figure.4.12}}
\newlabel{fg:regularization1}{{4.12}{71}{Results obtained from applying the regularized fitting algorithm}{figure.4.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.13}{\ignorespaces The fitting algorithm is prone to overfitting when no regularization is performed ($\lambda =0$) and there is only a small number of feature points available.}}{72}{figure.4.13}}
\newlabel{fg:regularization2}{{4.13}{72}{The fitting algorithm is prone to overfitting when no regularization is performed ($\lambda =0$) and there is only a small number of feature points available}{figure.4.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.14}{\ignorespaces Result obtained using the constrained fitting algorithm}}{72}{figure.4.14}}
\newlabel{fg:constrained1}{{4.14}{72}{Result obtained using the constrained fitting algorithm\relax }{figure.4.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.15}{\ignorespaces Using a larger number of automatically generated feature points, the constrained algorithm correctly perceives the facial dynamics, but misidentifies the expression as fear.}}{73}{figure.4.15}}
\newlabel{fg:constrained2}{{4.15}{73}{Using a larger number of automatically generated feature points, the constrained algorithm correctly perceives the facial dynamics, but misidentifies the expression as fear}{figure.4.15}{}}
\@writefile{toc}{\contentsline {paragraph}{Video Length.}{73}{section*.34}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Expression Transfer Results}{73}{section.4.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.16}{\ignorespaces Expression transfer by reanimating the augmented target subject with texture data obtained from the first target recording frame.}}{74}{figure.4.16}}
\newlabel{fg:transfer}{{4.16}{74}{Expression transfer by reanimating the augmented target subject with texture data obtained from the first target recording frame}{figure.4.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.17}{\ignorespaces Transfer of a smile using the first frame of the target recording as texture.}}{74}{figure.4.17}}
\newlabel{fg:transfer2}{{4.17}{74}{Transfer of a smile using the first frame of the target recording as texture}{figure.4.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.18}{\ignorespaces The cloning of the smile from the source (left) image into the target (right) image.}}{74}{figure.4.18}}
\newlabel{fg:poisson1}{{4.18}{74}{The cloning of the smile from the source (left) image into the target (right) image}{figure.4.18}{}}
\citation{faceTransfer05}
\@writefile{lof}{\contentsline {figure}{\numberline {4.19}{\ignorespaces Another example of using poisson cloning to achieve a somewhat realistic expression transfer result.}}{75}{figure.4.19}}
\newlabel{fg:poisson2}{{4.19}{75}{Another example of using poisson cloning to achieve a somewhat realistic expression transfer result}{figure.4.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.20}{\ignorespaces Texture transfer using poisson cloning. Depicted is a case where the techinque does not work well due to the discrepancy in size.}}{75}{figure.4.20}}
\newlabel{poisson3}{{4.20}{75}{Texture transfer using poisson cloning. Depicted is a case where the techinque does not work well due to the discrepancy in size}{figure.4.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Performance}{76}{section.4.5}}
\citation{viola}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusion}{77}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Future Work}{77}{section.5.1}}
\bibstyle{plain}
\bibdata{references}
\bibcite{FEMbook}{1}
\bibcite{kanade3}{2}
\bibcite{bishop}{3}
\bibcite{blanz1}{4}
\bibcite{blanz2}{5}
\bibcite{kanade4}{6}
\bibcite{opencv}{7}
\bibcite{projection}{8}
\bibcite{nnls2}{9}
\bibcite{cootesOverview01}{10}
\bibcite{activeApp04}{11}
\bibcite{POSIT}{12}
\bibcite{matcalc}{13}
\bibcite{ifemcolorado}{14}
\bibcite{nnls}{15}
\bibcite{lda}{16}
\bibcite{graphics}{17}
\bibcite{matrix}{18}
\bibcite{multilinear}{19}
\bibcite{poisson}{20}
\bibcite{kanade}{21}
\bibcite{FEM1ter}{22}
\bibcite{jacey}{23}
\bibcite{sdm}{24}
\bibcite{FEM1pen}{25}
\bibcite{perez}{26}
\bibcite{Press1992}{27}
\bibcite{vienna}{28}
\bibcite{ICP}{29}
\bibcite{Nelder2009}{30}
\bibcite{opengl}{31}
\bibcite{kronecker}{32}
\bibcite{deformTri}{33}
\bibcite{kanade2}{34}
\bibcite{eigenfaces91}{35}
\bibcite{Ter1}{36}
\bibcite{Ter3}{37}
\bibcite{Ter2}{38}
\bibcite{viola}{39}
\bibcite{faceTransfer05}{40}
\bibcite{binghamton}{41}
\bibcite{zhang}{42}
